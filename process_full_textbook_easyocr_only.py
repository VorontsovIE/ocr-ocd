#!/usr/bin/env python3
"""
OCR-OCD EasyOCR-Only Version
============================

–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ EasyOCR –¥–∞–Ω–Ω—ã–µ
–†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ API –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
"""

import sys
import json
import time
import click
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import re

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.utils.logger import setup_development_logger, setup_production_logger, get_logger
from src.utils.easyocr_parser import EasyOCRParser


class EasyOCRTaskExtractor:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –∏–∑ EasyOCR –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(self, ocr_file_path: str):
        self.ocr_parser = EasyOCRParser(ocr_file_path)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
        self.task_patterns = [
            r'—Å–∫–æ–ª—å–∫–æ.*\?',
            r'—Ä–µ—à–∏.*',
            r'–Ω–∞–π–¥–∏.*',
            r'–≤—ã—á–∏—Å–ª–∏.*',
            r'–ø–æ—Å—á–∏—Ç–∞–π.*',
            r'\d+\s*[+\-√ó√∑]\s*\d+',
            r'–±–æ–ª—å—à–µ.*–º–µ–Ω—å—à–µ',
            r'–¥–ª–∏–Ω–Ω–µ–µ.*–∫–æ—Ä–æ—á–µ',
            r'–∑–∞–¥–∞—á[–∞–∏].*',
            r'–ø—Ä–∏–º–µ—Ä.*',
            r'—É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ.*'
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è has_image
        self.image_keywords = [
            '—Ä–∏—Å—É–Ω', '–∫–∞—Ä—Ç–∏–Ω', '—Å—Ö–µ–º', '–¥–∏–∞–≥—Ä–∞–º–º', '–≥—Ä–∞—Ñ–∏–∫', '—á–µ—Ä—Ç—ë–∂', 
            '–ø–æ–∫–∞–∂–∏', '–Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–æ', '–∏–∑–æ–±—Ä–∞–∂', '–≤–∏–¥–∏—à—å'
        ]
        
    def extract_tasks_from_page(self, page_number: int) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ EasyOCR."""
        
        try:
            start_time = time.time()
            
            # –ü–æ–ª—É—á–∞–µ–º OCR –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            ocr_page = self.ocr_parser.parse_page(page_number)
            
            if not ocr_page:
                return {
                    "page_number": page_number,
                    "tasks": [],
                    "processing_time": time.time() - start_time,
                    "method": "easyocr_only",
                    "error": "No OCR data found"
                }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–¥–∞—á–∏
            tasks = self._extract_math_tasks(ocr_page)
            
            processing_time = time.time() - start_time
            
            return {
                "page_number": page_number,
                "tasks": tasks,
                "processing_time": processing_time,
                "method": "easyocr_only",
                "ocr_stats": {
                    "total_words": ocr_page.word_count,
                    "total_lines": len(ocr_page.lines),
                    "avg_confidence": round(ocr_page.avg_confidence, 1),
                    "numbers_found": ocr_page.get_numbers_and_operators()[:10]
                },
                "full_text": ocr_page.text
            }
            
        except Exception as e:
            return {
                "page_number": page_number,
                "tasks": [],
                "processing_time": 0,
                "method": "easyocr_only",
                "error": str(e)
            }
    
    def _extract_math_tasks(self, ocr_page) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –∏–∑ OCR –¥–∞–Ω–Ω—ã—Ö."""
        
        tasks = []
        full_text = ocr_page.text.lower()
        lines = ocr_page.text.split('\n')
        
        # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        pattern_tasks = self._find_pattern_tasks(lines)
        tasks.extend(pattern_tasks)
        
        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫ —Å —á–∏—Å–ª–∞–º–∏ –∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
        number_tasks = self._find_number_tasks(lines, ocr_page)
        tasks.extend(number_tasks)
        
        # –ú–µ—Ç–æ–¥ 3: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–¥–ª–∏–Ω–Ω—ã–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã)
        context_tasks = self._find_context_tasks(lines)
        tasks.extend(context_tasks)
        
        # –ï—Å–ª–∏ –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞—ë–º –æ–±—â—É—é –∑–∞–¥–∞—á—É –∏–∑ –≤—ã—Å–æ–∫–æ—Ç–æ—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if not tasks:
            high_conf_text = ocr_page.get_high_confidence_text()
            if high_conf_text and len(high_conf_text.strip()) > 10:
                tasks.append({
                    "task_number": "page-content-1",
                    "task_text": high_conf_text[:300],
                    "has_image": self._has_image_indicators(high_conf_text),
                    "confidence_score": ocr_page.avg_confidence / 100,
                    "extraction_method": "high_confidence_content"
                })
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —É–ª—É—á—à–∞–µ–º –∑–∞–¥–∞—á–∏
        tasks = self._clean_and_improve_tasks(tasks, ocr_page)
        
        return tasks
    
    def _find_pattern_tasks(self, lines: List[str]) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –∑–∞–¥–∞—á –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º."""
        tasks = []
        task_num = 1
        
        for line in lines:
            line_clean = line.strip()
            if len(line_clean) < 5:
                continue
            
            line_lower = line_clean.lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            for pattern in self.task_patterns:
                if re.search(pattern, line_lower):
                    tasks.append({
                        "task_number": f"pattern-{task_num}",
                        "task_text": line_clean,
                        "has_image": self._has_image_indicators(line_lower),
                        "confidence_score": 0.8,
                        "extraction_method": f"pattern_match_{pattern[:10]}"
                    })
                    task_num += 1
                    break
        
        return tasks
    
    def _find_number_tasks(self, lines: List[str], ocr_page) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –∑–∞–¥–∞—á —Å —á–∏—Å–ª–∞–º–∏ –∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏."""
        tasks = []
        numbers = ocr_page.get_numbers_and_operators()
        
        if not numbers:
            return tasks
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —á–∏—Å–ª–∞
        number_lines = []
        for line in lines:
            line_clean = line.strip()
            if len(line_clean) < 3:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —á–∏—Å–ª–∞ –≤ —Å—Ç—Ä–æ–∫–µ
            has_numbers = any(num in line_clean for num in numbers if num.isdigit())
            has_operators = any(op in line_clean for op in ['+', '-', '=', '>', '<', '√ó', '√∑'])
            
            if has_numbers or has_operators:
                number_lines.append(line_clean)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –±–ª–∏–∑–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ –∑–∞–¥–∞—á–∏
        task_num = 1
        for line in number_lines:
            if len(line) > 5:
                tasks.append({
                    "task_number": f"math-{task_num}",
                    "task_text": line,
                    "has_image": self._has_image_indicators(line.lower()),
                    "confidence_score": 0.7,
                    "extraction_method": "number_analysis"
                })
                task_num += 1
        
        return tasks
    
    def _find_context_tasks(self, lines: List[str]) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã)."""
        tasks = []
        
        # –ò—â–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        meaningful_lines = []
        for line in lines:
            line_clean = line.strip()
            
            # –§–∏–ª—å—Ç—Ä—ã –¥–ª—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            if (len(line_clean) > 15 and 
                not line_clean.isupper() and  # –ù–µ —Ç–æ–ª—å–∫–æ –∑–∞–≥–ª–∞–≤–Ω—ã–µ
                ' ' in line_clean and  # –ï—Å—Ç—å –ø—Ä–æ–±–µ–ª—ã
                any(char.isalpha() for char in line_clean)):  # –ï—Å—Ç—å –±—É–∫–≤—ã
                
                meaningful_lines.append(line_clean)
        
        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        task_num = 1
        for line in meaningful_lines[:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –∑–∞–¥–∞—á–∏
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ —Å–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            line_lower = line.lower()
            if not any(skip in line_lower for skip in ['–∏–∑–¥–∞–Ω–∏–µ', '–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ', '—É—á–ø–µ–¥–≥–∏–∑', '—Å—Ç—Ä–∞–Ω–∏—Ü–∞']):
                tasks.append({
                    "task_number": f"context-{task_num}",
                    "task_text": line,
                    "has_image": self._has_image_indicators(line_lower),
                    "confidence_score": 0.6,
                    "extraction_method": "context_analysis"
                })
                task_num += 1
        
        return tasks
    
    def _has_image_indicators(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ."""
        text_lower = text.lower()
        return any(keyword in text_lower for keyword in self.image_keywords)
    
    def _clean_and_improve_tasks(self, tasks: List[Dict], ocr_page) -> List[Dict]:
        """–û—á–∏—â–∞–µ—Ç –∏ —É–ª—É—á—à–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏."""
        
        if not tasks:
            return tasks
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É
        seen_texts = set()
        unique_tasks = []
        
        for task in tasks:
            text = task['task_text'].strip()
            if text and text not in seen_texts:
                seen_texts.add(text)
                unique_tasks.append(task)
        
        # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∑–∞–¥–∞—á–∏
        for i, task in enumerate(unique_tasks, 1):
            if task['task_number'].startswith(('pattern-', 'math-', 'context-')):
                task['task_number'] = f"easyocr-{i}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ OCR
        for task in unique_tasks:
            task.update({
                "page_ocr_confidence": round(ocr_page.avg_confidence, 1),
                "page_word_count": ocr_page.word_count,
                "extraction_source": "easyocr_analysis"
            })
        
        return unique_tasks


class IntermediateStorage:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    
    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
    def save_page_result(self, page_number: int, page_data: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        file_path = self.storage_dir / f"page_{page_number:03d}.json"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        page_data.update({
            'processed_at': datetime.now().isoformat(),
            'page_number': page_number,
            'storage_version': '2.3-easyocr-only'
        })
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(page_data, f, ensure_ascii=False, indent=2)
    
    def load_page_result(self, page_number: int) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        file_path = self.storage_dir / f"page_{page_number:03d}.json"
        
        if not file_path.exists():
            return None
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}")
            return None
    
    def get_processed_pages(self) -> List[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü."""
        processed = []
        
        for file_path in sorted(self.storage_dir.glob("page_*.json")):
            try:
                page_num = int(file_path.stem.split('_')[1])
                processed.append(page_num)
            except (ValueError, IndexError):
                continue
                
        return sorted(processed)
    
    def load_all_results(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        results = []
        
        for page_num in self.get_processed_pages():
            page_data = self.load_page_result(page_num)
            if page_data:
                results.append(page_data)
        
        return results
    
    def clear_storage(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã."""
        for file_path in self.storage_dir.glob("page_*.json"):
            file_path.unlink()


@click.command()
@click.argument('ocr_file', type=click.Path(exists=True))
@click.argument('output_csv', type=click.Path())
@click.option('--force', is_flag=True, help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã')
@click.option('--start-page', type=int, default=1, help='–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--end-page', type=int, default=None, help='–ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--production', is_flag=True, help='Production —Ä–µ–∂–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è')
@click.option('--verbose', is_flag=True, help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
def process_textbook_easyocr_only(ocr_file, output_csv, force, start_page, end_page, production, verbose):
    """
    OCR-OCD EasyOCR-Only: –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ API –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π.
    
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ EasyOCR –¥–∞–Ω–Ω—ã–µ.
    """
    
    print("üöÄüìö OCR-OCD EasyOCR-Only: –ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
    print("=" * 55)
    print(f"üîç EasyOCR —Ñ–∞–π–ª: {ocr_file}")
    print(f"üìä –í—ã–≤–æ–¥: {output_csv}")
    print(f"üîÑ Force —Ä–µ–∂–∏–º: {'‚úÖ' if force else '‚ùå'}")
    print(f"üö´ –ë–µ–∑ API –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: ‚úÖ")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if production:
        setup_production_logger()
    else:
        setup_development_logger()
    
    logger = get_logger(__name__)
    
    # –°–æ–∑–¥–∞—ë–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    paths = {
        'output': Path("output"),
        'temp': Path("temp"), 
        'logs': Path("logs"),
        'storage': Path("temp/processed_pages_easyocr_only")
    }
    
    for path in paths.values():
        path.mkdir(parents=True, exist_ok=True)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    storage = IntermediateStorage(paths['storage'])
    
    if force:
        print("üóëÔ∏è  Force —Ä–µ–∂–∏–º: –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        storage.clear_storage()
    
    start_time = datetime.now()
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EasyOCR —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
        print(f"üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EasyOCR —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞...")
        extractor = EasyOCRTaskExtractor(ocr_file)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        available_pages = extractor.ocr_parser.get_available_pages()
        
        if end_page is None:
            end_page = max(available_pages) if available_pages else start_page
        else:
            end_page = min(end_page, max(available_pages) if available_pages else end_page)
        
        print(f"‚úÖ EasyOCR –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(available_pages)} —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ—Å—Ç—É–ø–Ω–æ")
        print(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü—ã {start_page}-{end_page}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        processed_pages = set(storage.get_processed_pages())
        
        if processed_pages and not force:
            print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(processed_pages)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")
            print(f"üìä –ü–æ—Å–ª–µ–¥–Ω—è—è: {max(processed_pages) if processed_pages else 'none'}")
        
        # –°—á—ë—Ç—á–∏–∫–∏
        processed_count = 0
        skipped_count = 0 
        error_count = 0
        total_tasks = 0
        
        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º EasyOCR-only –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        
        for page_num in range(start_page, end_page + 1):
            page_start_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if page_num not in available_pages:
                if verbose:
                    print(f"‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–µ—Ç OCR –¥–∞–Ω–Ω—ã—Ö")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
            if not force and page_num in processed_pages:
                skipped_count += 1
                if verbose:
                    print(f"‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞)")
                continue
            
            try:
                progress = (page_num - start_page + 1) / (end_page - start_page + 1) * 100
                print(f"\nüìñ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{end_page} ({progress:.1f}%)")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ EasyOCR —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
                if verbose:
                    print(f"  üîç EasyOCR –∞–Ω–∞–ª–∏–∑...")
                
                result = extractor.extract_tasks_from_page(page_num)
                
                if 'error' in result:
                    error_count += 1
                    print(f"     ‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                    continue
                
                tasks = result['tasks']
                ocr_stats = result.get('ocr_stats', {})
                
                if verbose:
                    print(f"  ‚úÖ OCR –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
                    print(f"  üìä –°–ª–æ–≤: {ocr_stats.get('total_words', 0)}, "
                          f"–°—Ç—Ä–æ–∫: {ocr_stats.get('total_lines', 0)}, "
                          f"Confidence: {ocr_stats.get('avg_confidence', 0)}%")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                page_result = {
                    'page_number': page_num,
                    'tasks': tasks,
                    'processing_time': result['processing_time'],
                    'ocr_stats': ocr_stats,
                    'api_method': 'easyocr_only',
                    'task_count': len(tasks),
                    'full_text': result.get('full_text', '')
                }
                
                storage.save_page_result(page_num, page_result)
                
                processed_count += 1
                total_tasks += len(tasks)
                
                processing_time = time.time() - page_start_time
                print(f"     ‚úÖ –ó–∞–¥–∞—á: {len(tasks)}, –í—Ä–µ–º—è: {processing_time:.1f}s")
                
                if verbose and tasks:
                    for i, task in enumerate(tasks, 1):
                        method = task.get('extraction_method', 'unknown')
                        print(f"       {i}. [{method}] {task['task_number']}: {task['task_text'][:60]}...")
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"Error processing page {page_num}: {e}")
                print(f"     ‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                error_count += 1
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüíæ –°–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        all_results = storage.load_all_results()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ CSV
        if all_results:
            print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ EasyOCR-only CSV —Ñ–∞–π–ª–∞...")
            create_easyocr_csv(all_results, output_csv)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = (datetime.now() - start_time).total_seconds()
        
        print(f"\nüéâ EASYOCR-ONLY –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"=" * 50)
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   üìö –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}")
        print(f"   ‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
        print(f"   ‚ùå –û—à–∏–±–æ–∫: {error_count}")
        print(f"   üìù –ó–∞–¥–∞—á –∏–∑–≤–ª–µ—á–µ–Ω–æ: {total_tasks}")
        print(f"   üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: $0.00 (–±–µ—Å–ø–ª–∞—Ç–Ω–æ!)")
        print(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}s ({total_time/60:.1f} –º–∏–Ω—É—Ç)")
        if processed_count > 0:
            print(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {processed_count/total_time*60:.1f} —Å—Ç—Ä–∞–Ω–∏—Ü/–º–∏–Ω—É—Ç—É")
            print(f"   üìà –°—Ä–µ–¥–Ω–µ–µ –∑–∞–¥–∞—á/—Å—Ç—Ä–∞–Ω–∏—Ü–∞: {total_tasks/processed_count:.1f}")
        print(f"   üìÅ EasyOCR CSV: {output_csv}")
        
        return True
        
    except Exception as e:
        logger.error(f"Critical error: {e}")
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False


def create_easyocr_csv(results: List[Dict], output_path: str) -> None:
    """–°–æ–∑–¥–∞—ë—Ç CSV —Ñ–∞–π–ª –∏–∑ EasyOCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    
    all_tasks = []
    
    for page_result in results:
        page_num = page_result['page_number']
        processing_time = page_result.get('processing_time', 0)
        ocr_stats = page_result.get('ocr_stats', {})
        
        for task_data in page_result.get('tasks', []):
            task_row = {
                'page_number': page_num,
                'task_number': task_data.get('task_number', 'unknown'),
                'task_text': task_data.get('task_text', ''),
                'has_image': task_data.get('has_image', False),
                'confidence_score': task_data.get('confidence_score', 0.0),
                'processing_time': processing_time,
                'api_method': 'easyocr_only',
                'extraction_method': task_data.get('extraction_method', 'unknown'),
                'page_ocr_confidence': task_data.get('page_ocr_confidence', 0),
                'page_word_count': task_data.get('page_word_count', 0),
                'extraction_source': task_data.get('extraction_source', 'easyocr'),
                'extracted_at': page_result.get('processed_at', ''),
                'word_count': len(task_data.get('task_text', '').split()),
                'system_type': 'easyocr_standalone'
            }
            all_tasks.append(task_row)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_tasks.sort(key=lambda x: x['page_number'])
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV
    import csv
    with open(output_path, 'w', newline='', encoding='utf-8') as f:
        if all_tasks:
            fieldnames = list(all_tasks[0].keys())
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_tasks)
    
    print(f"‚úÖ EasyOCR CSV —Å–æ–∑–¥–∞–Ω: {len(all_tasks)} –∑–∞–¥–∞—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
    print(f"üìä –ü–æ–ª—è: extraction_method, page_ocr_confidence, system_type")


if __name__ == "__main__":
    process_textbook_easyocr_only() 