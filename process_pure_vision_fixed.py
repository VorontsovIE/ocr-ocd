#!/usr/bin/env python3
"""
OCR-OCD Pure Vision Fixed: –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è OpenAI
==================================================

–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —á–∏—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞:
- üìñ PDF ‚Üí –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü
- üñºÔ∏è –ü—Ä—è–º–æ–π GPT-4 Vision API ‚Üí –∞–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á  
- üìä CSV ‚Üí —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–° —Ä–∞–±–æ—á–µ–π –ø—Ä—è–º–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π OpenAI!
"""

import sys
import json
import time
import base64
import os
import click
import openai
import asyncio
import concurrent.futures
import hashlib
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from PIL import Image, ImageEnhance, ImageFilter
import io

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.core.pdf_processor import PDFProcessor
from src.core.vision_adapters import VisionAdapterFactory, VisionProvider
from src.utils.logger import setup_development_logger, setup_production_logger, get_logger
from src.utils.config import APIConfig


class FileIdentifier:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ñ–∞–π–ª–æ–≤"""
    
    @staticmethod
    def generate(pdf_path: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è PDF —Ñ–∞–π–ª–∞.
        
        Args:
            pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
            
        Returns:
            –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ "basename_md5hash"
        """
        file_path = Path(pdf_path)
        basename = file_path.stem
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º MD5 —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        hash_md5 = hashlib.md5()
        with open(pdf_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        
        file_hash = hash_md5.hexdigest()[:8]
        clean_basename = "".join(c for c in basename if c.isalnum() or c in "_-")[:20]
        
        return f"{clean_basename}_{file_hash}"


class ImageSplitter:
    """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    
    @staticmethod
    def split_image(image_data: bytes, split_mode: str = "vertical") -> List[bytes]:
        """
        –†–∞–∑–¥–µ–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–Ω–æ–≥–æ–∫–æ–ª–æ–Ω–æ—á–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.
        
        Args:
            image_data: –î–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            split_mode: –†–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è ("original", "vertical", "horizontal", "grid")
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞—Å—Ç–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        if split_mode == "original":
            return [image_data]
        
        image = Image.open(io.BytesIO(image_data))
        width, height = image.size
        parts = []
        
        if split_mode == "vertical":
            # –†–∞–∑–¥–µ–ª—è–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ –Ω–∞ 2 —á–∞—Å—Ç–∏ (–ª–µ–≤–∞—è/–ø—Ä–∞–≤–∞—è)
            left_part = image.crop((0, 0, width // 2, height))
            right_part = image.crop((width // 2, 0, width, height))
            
            for part in [left_part, right_part]:
                buffer = io.BytesIO()
                part.save(buffer, format='PNG', quality=95)
                parts.append(buffer.getvalue())
                
        elif split_mode == "horizontal":
            # –†–∞–∑–¥–µ–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ –Ω–∞ 2 —á–∞—Å—Ç–∏ (–≤–µ—Ä—Ö–Ω—è—è/–Ω–∏–∂–Ω—è—è)
            top_part = image.crop((0, 0, width, height // 2))
            bottom_part = image.crop((0, height // 2, width, height))
            
            for part in [top_part, bottom_part]:
                buffer = io.BytesIO()
                part.save(buffer, format='PNG', quality=95)
                parts.append(buffer.getvalue())
                
        elif split_mode == "grid":
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Å–µ—Ç–∫—É 2x2
            for i in range(2):
                for j in range(2):
                    part = image.crop((
                        i * width // 2, 
                        j * height // 2, 
                        (i + 1) * width // 2, 
                        (j + 1) * height // 2
                    ))
                    buffer = io.BytesIO()
                    part.save(buffer, format='PNG', quality=95)
                    parts.append(buffer.getvalue())
        
        return parts


class ImageEnhancer:
    """–£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è OCR"""
    
    @staticmethod
    def enhance_image(image_data: bytes) -> bytes:
        """
        –£–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
        
        Args:
            image_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            –£–ª—É—á—à–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        image = Image.open(io.BytesIO(image_data))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.5)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–µ–∑–∫–æ—Å—Ç—å
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.3)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —è—Ä–∫–æ—Å—Ç—å
        enhancer = ImageEnhance.Brightness(image)
        image = enhancer.enhance(1.1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        buffer = io.BytesIO()
        image.save(buffer, format='PNG', quality=95)
        return buffer.getvalue()


class VisionAPI:
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ API"""
    
    def __init__(self, provider: VisionProvider = VisionProvider.GEMINI, images_dir: Optional[Path] = None):
        load_dotenv()
        self.provider = provider
        self.images_dir = images_dir or Path("temp/images")
        self.images_dir.mkdir(parents=True, exist_ok=True)
        self.logger = get_logger(__name__)
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é API
        api_key = None
        model_name = "gpt-4-vision-preview"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è OpenAI
        
        if provider == VisionProvider.OPENAI:
            api_key = os.getenv("OPENAI_API_KEY")
            model_name = "gpt-4-vision-preview"
        elif provider == VisionProvider.GEMINI:
            api_key = os.getenv("GEMINI_API_KEY")
            model_name = "gemini-2.0-flash-exp"
        elif provider == VisionProvider.CLAUDE:
            api_key = os.getenv("CLAUDE_API_KEY")
            model_name = "claude-3-5-sonnet-20241022"
        
        if not api_key:
            raise ValueError(f"API key for {provider.value} is required")
        
        self.api_config = APIConfig(
            provider=provider.value,
            api_key=api_key,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            gemini_api_key=os.getenv("GEMINI_API_KEY"),
            claude_api_key=os.getenv("CLAUDE_API_KEY"),
            model_name=model_name
        )
        
        # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        self.adapter = VisionAdapterFactory.create_adapter(provider, self.api_config)
        
    def _save_image_to_disk(self, image_data: bytes, filename: str, subfolder: str = "") -> Optional[Path]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –¥–∏—Å–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        try:
            subfolder_path = self.images_dir / subfolder
            subfolder_path.mkdir(parents=True, exist_ok=True)
            
            file_path = subfolder_path / filename
            with open(file_path, 'wb') as f:
                f.write(image_data)
            return file_path
        except Exception as e:
            get_logger(__name__).warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")
            return None
    
    def _enhance_image_for_ocr(self, image_data: bytes) -> bytes:
        """–£–ª—É—á—à–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è OCR"""
        return ImageEnhancer.enhance_image(image_data)
    
    def extract_tasks_from_page(self, image_data: bytes, page_number: int, 
                               use_split_analysis: bool = True, split_mode: str = "vertical") -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π API.
        
        Args:
            image_data: –î–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_number: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            use_split_analysis: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            split_mode: –†–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        enhanced_image_data = self._enhance_image_for_ocr(image_data)
        
        if use_split_analysis:
            return self._analyze_with_split_method(enhanced_image_data, page_number, split_mode)
        else:
            return self._analyze_whole_image(enhanced_image_data, page_number)
    
    def _analyze_with_split_method(self, enhanced_image_data: bytes, page_number: int, 
                                  split_mode: str = "vertical") -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —á–∞—Å—Ç–∏"""
        image_parts = ImageSplitter.split_image(enhanced_image_data, split_mode)
        
        all_tasks = []
        part_results = []
        has_errors = False
        max_retry_delay = None
        
        for i, part_data in enumerate(image_parts):
            part_name = f"part_{i+1}"
            part_result = self._analyze_image_part(part_data, page_number, part_name, i+1)
            part_results.append(part_result)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ –≤ —á–∞—Å—Ç—è—Ö
            if part_result.get("error"):
                has_errors = True
                self.logger.error(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}, —á–∞—Å—Ç—å {part_name}: {part_result['error']}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º retry_delay –≤ —á–∞—Å—Ç—è—Ö
            if part_result.get("retry_delay"):
                retry_delay = part_result["retry_delay"]
                if max_retry_delay is None or retry_delay > max_retry_delay:
                    max_retry_delay = retry_delay
            
            if part_result.get("tasks"):
                all_tasks.extend(part_result["tasks"])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        combined_result = {
            "page_number": page_number,
            "analysis_method": f"split_{split_mode}",
            "parts_analyzed": len(image_parts),
            "tasks": all_tasks,
            "part_results": part_results,
            "total_tasks": len(all_tasks),
            "timestamp": datetime.now().isoformat()
        }
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏ –≤ —á–∞—Å—Ç—è—Ö, –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é –æ—à–∏–±–∫—É
        if has_errors:
            combined_result["error"] = f"–û—à–∏–±–∫–∏ –≤ {len([p for p in part_results if p.get('error')])} –∏–∑ {len(part_results)} —á–∞—Å—Ç–µ–π"
        
        # –ü–µ—Ä–µ–¥–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π retry_delay –∏–∑ —á–∞—Å—Ç–µ–π
        if max_retry_delay:
            combined_result["retry_delay"] = max_retry_delay
        
        return combined_result
    
    def _analyze_image_part(self, part_data: bytes, page_number: int, 
                           part_name: str, part_number: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —á–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            debug_filename = f"page_{page_number}_{part_name}.png"
            self._save_image_to_disk(part_data, debug_filename, f"page_{page_number}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            prompt = f"""–ù–∞–π–¥–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number} (—á–∞—Å—Ç—å {part_number}). –í–µ—Ä–Ω–∏ JSON:
{{
    "tasks": [
        {{
            "number": "–Ω–æ–º–µ—Ä",
            "text": "—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏",
            "type": "—Ç–∏–ø",
            "difficulty": "—Å–ª–æ–∂–Ω–æ—Å—Ç—å",
            "part": "{part_name}"
        }}
    ]
}}"""
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
            result = self.adapter.extract_tasks_from_page(
                image_data=part_data,
                page_number=page_number,
                prompt=prompt
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            result.update({
                "page_number": page_number,
                "part_name": part_name,
                "part_number": part_number,
                "analysis_method": f"{self.provider.value}_api_split",
                "timestamp": datetime.now().isoformat()
            })
            
            return result
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–∏ {part_name}: {e}")
            return {
                "page_number": page_number,
                "part_name": part_name,
                "part_number": part_number,
                "tasks": [],
                "error": str(e),
                "analysis_method": f"{self.provider.value}_api_split",
                "timestamp": datetime.now().isoformat()
            }
    
    def _analyze_whole_image(self, enhanced_image_data: bytes, page_number: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ü–µ–ª–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            debug_filename = f"page_{page_number}_whole.png"
            self._save_image_to_disk(enhanced_image_data, debug_filename, f"page_{page_number}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            prompt = f"""–ù–∞–π–¥–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_number}. –í–µ—Ä–Ω–∏ JSON:
{{
    "tasks": [
        {{
            "number": "–Ω–æ–º–µ—Ä",
            "text": "—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏",
            "type": "—Ç–∏–ø",
            "difficulty": "—Å–ª–æ–∂–Ω–æ—Å—Ç—å"
        }}
    ]
}}"""
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
            result = self.adapter.extract_tasks_from_page(
                image_data=enhanced_image_data,
                page_number=page_number,
                prompt=prompt
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            result.update({
                "page_number": page_number,
                "analysis_method": f"{self.provider.value}_api_whole",
                "timestamp": datetime.now().isoformat()
            })
            
            return result
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}")
            return {
                "page_number": page_number,
                "tasks": [],
                "error": str(e),
                "analysis_method": f"{self.provider.value}_api_whole",
                "timestamp": datetime.now().isoformat()
            }
    
    def _create_fallback_structure(self, content: str, page_number: int) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON"""
        return {
            "page_number": page_number,
            "tasks": [
                {
                    "number": "fallback_1",
                    "text": content[:500] + "..." if len(content) > 500 else content,
                    "type": "–∑–∞–¥–∞—á–∞",
                    "difficulty": "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                    "note": "–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ API"
                }
            ],
            "analysis_method": "fallback",
            "timestamp": datetime.now().isoformat()
        }


class ParallelProcessor:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü"""
    
    def __init__(self, max_concurrent_requests: int = 5, requests_per_minute: int = 80):
        self.max_concurrent_requests = max_concurrent_requests
        self.requests_per_minute = requests_per_minute
        self.semaphore = asyncio.Semaphore(max_concurrent_requests)
        self.request_times = []
        self.logger = get_logger(__name__)
    
    async def _wait_for_rate_limit(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API"""
        current_time = time.time()
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ (—Å—Ç–∞—Ä—à–µ 1 –º–∏–Ω—É—Ç—ã)
        self.request_times = [t for t in self.request_times if current_time - t < 60]
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞, –∂–¥–µ–º
        if len(self.request_times) >= self.requests_per_minute:
            wait_time = 60 - (current_time - self.request_times[0])
            if wait_time > 0:
                self.logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤, –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time:.1f} —Å–µ–∫—É–Ω–¥")
                await asyncio.sleep(wait_time)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –ø–ª–∞–Ω–∞
        if self.requests_per_minute <= 60:  # –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ø–ª–∞–Ω
            await asyncio.sleep(1)  # 1 —Å–µ–∫—É–Ω–¥–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
        self.request_times.append(current_time)
    
    async def process_page_async(self, vision_api: VisionAPI, image_data: bytes, 
                                page_number: int, split_mode: str = "vertical") -> Dict[str, Any]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        async with self.semaphore:
            await self._wait_for_rate_limit()
            
            try:
                result = vision_api.extract_tasks_from_page(
                    image_data, page_number, 
                    use_split_analysis=True, 
                    split_mode=split_mode
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º retry_delay –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                if result.get("retry_delay"):
                    retry_delay = result["retry_delay"]
                    self.logger.warning(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}: API —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É {retry_delay} —Å–µ–∫—É–Ω–¥")
                    await asyncio.sleep(retry_delay)
                
                self.logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                return result
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}")
                return {
                    "page_number": page_number,
                    "tasks": [],
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
    
    async def process_pages_batch(self, vision_api: VisionAPI, pages_data: List[tuple], 
                                 split_mode: str = "vertical") -> List[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü"""
        tasks = []
        
        for image_data, page_number in pages_data:
            task = self.process_page_async(vision_api, image_data, page_number, split_mode)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                page_number = pages_data[i][1]
                processed_results.append({
                    "page_number": page_number,
                    "tasks": [],
                    "error": str(result),
                    "timestamp": datetime.now().isoformat()
                })
            else:
                processed_results.append(result)
        
        return processed_results


class TaskExtractor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞–¥–∞—á –∏–∑ PDF"""
    
    def __init__(self, pdf_path: str, provider: VisionProvider = VisionProvider.GEMINI, images_dir: Optional[Path] = None):
        self.pdf_path = pdf_path
        self.file_identifier = FileIdentifier.generate(pdf_path)
        self.pdf_processor = PDFProcessor(pdf_path)
        self.vision_api = VisionAPI(provider, images_dir)
        self.logger = get_logger(__name__)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º PDF
        self.pdf_processor.load_pdf()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.temp_dir = Path("temp") / self.file_identifier
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
        if images_dir:
            self.images_dir = Path(images_dir)
            self.images_dir.mkdir(parents=True, exist_ok=True)
    
    def extract_tasks_from_page(self, page_number: int, use_split_analysis: bool = True, 
                               split_mode: str = "vertical") -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
        
        Args:
            page_number: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            use_split_analysis: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            split_mode: –†–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        try:
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            image_data = self.pdf_processor.convert_page_to_image(page_number)
            
            if image_data is None:
                self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}")
                return {
                    "page_number": page_number,
                    "tasks": [],
                    "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã",
                    "timestamp": datetime.now().isoformat()
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            result = self.vision_api.extract_tasks_from_page(
                image_data, page_number, use_split_analysis, split_mode
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            result["file_identifier"] = self.file_identifier
            result["pdf_path"] = str(self.pdf_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
            if result.get("error"):
                self.logger.error(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}: {result['error']}")
            else:
                self.logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: –Ω–∞–π–¥–µ–Ω–æ {len(result.get('tasks', []))} –∑–∞–¥–∞—á")
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}")
            return {
                "page_number": page_number,
                "tasks": [],
                "error": str(e),
                "file_identifier": self.file_identifier,
                "pdf_path": str(self.pdf_path),
                "timestamp": datetime.now().isoformat()
            }
    
    def get_total_pages(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ PDF"""
        return self.pdf_processor.get_page_count()
    
    def _calculate_confidence(self, task_data: Dict[str, Any], api_result: Dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∞–Ω–∞–ª–∏–∑–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        confidence = 0.5  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        
        if api_result.get("tasks"):
            confidence += 0.3
        
        if not api_result.get("error"):
            confidence += 0.2
        
        return min(confidence, 1.0)


class ResultStorage:
    """–•—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
    
    def save_page_result(self, page_number: int, page_data: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        filename = f"page_{page_number:04d}.json"
        file_path = self.storage_dir / filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(page_data, f, ensure_ascii=False, indent=2)
    
    def load_page_result(self, page_number: int) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        filename = f"page_{page_number:04d}.json"
        file_path = self.storage_dir / filename
        
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def get_processed_pages(self) -> List[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        processed = []
        for file_path in self.storage_dir.glob("page_*.json"):
            try:
                page_num = int(file_path.stem.split('_')[1])
                processed.append(page_num)
            except (ValueError, IndexError):
                continue
        return sorted(processed)
    
    def get_successful_pages(self) -> List[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–±–µ–∑ –æ—à–∏–±–æ–∫)"""
        successful = []
        for page_num in self.get_processed_pages():
            result = self.load_page_result(page_num)
            if result and not result.get("error"):
                successful.append(page_num)
        return successful
    
    def get_failed_pages(self) -> List[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –æ—à–∏–±–∫–∞–º–∏"""
        failed = []
        for page_num in self.get_processed_pages():
            result = self.load_page_result(page_num)
            if result and result.get("error"):
                failed.append(page_num)
        return failed
    
    def is_page_successful(self, page_number: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª–∞ –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞"""
        result = self.load_page_result(page_number)
        return result is not None and not result.get("error")
    
    def load_all_results(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        results = []
        for page_num in self.get_processed_pages():
            result = self.load_page_result(page_num)
            if result:
                results.append(result)
        return results
    
    def clear_storage(self) -> None:
        """–û—á–∏—â–∞–µ—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        for file_path in self.storage_dir.glob("page_*.json"):
            file_path.unlink()


async def process_pages_parallel(extractor: TaskExtractor, parallel_processor: ParallelProcessor, 
                               storage: ResultStorage, start_page: int, end_page: int, 
                               processed_pages: List[int], force: bool, verbose: bool, 
                               batch_size: int, split_mode: str):
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü"""
    logger = get_logger(__name__)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    pages_to_process = []
    for page_num in range(start_page, end_page + 1):
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –µ—Å–ª–∏:
        # 1. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ (force=True)
        # 2. –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Ä–∞–Ω–µ–µ
        # 3. –°—Ç—Ä–∞–Ω–∏—Ü–∞ –≤–æ–æ–±—â–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∞—Å—å
        should_process = force or page_num not in processed_pages
        
        if should_process:
            try:
                image_data = extractor.pdf_processor.convert_page_to_image(page_num)
                if image_data:
                    pages_to_process.append((image_data, page_num))
                    if verbose:
                        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        elif verbose:
            logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} —É–∂–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
    
    if not pages_to_process:
        logger.info("–ù–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return []
    
    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(pages_to_process)} —Å—Ç—Ä–∞–Ω–∏—Ü")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–∞–∫–µ—Ç–∞–º–∏
    all_results = []
    for i in range(0, len(pages_to_process), batch_size):
        batch = pages_to_process[i:i + batch_size]
        
        if verbose:
            page_numbers = [page_num for _, page_num in batch]
            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–∫–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: {page_numbers}")
        
        batch_results = await parallel_processor.process_pages_batch(
            extractor.vision_api, batch, split_mode
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in batch_results:
            page_num = result.get("page_number")
            if page_num:
                storage.save_page_result(page_num, result)
        
        all_results.extend(batch_results)
        
        if verbose:
            logger.info(f"–ü–∞–∫–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(batch_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    logger.info(f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(all_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    return all_results


def process_pages_sequential(extractor: TaskExtractor, storage: ResultStorage, 
                           start_page: int, end_page: int, processed_pages: List[int], 
                           force: bool, verbose: bool, split_mode: str):
    """–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü"""
    logger = get_logger(__name__)
    
    results = []
    for page_num in range(start_page, end_page + 1):
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –µ—Å–ª–∏:
        # 1. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ (force=True)
        # 2. –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Ä–∞–Ω–µ–µ
        # 3. –°—Ç—Ä–∞–Ω–∏—Ü–∞ –≤–æ–æ–±—â–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∞—Å—å
        should_process = force or page_num not in processed_pages
        
        if should_process:
            if verbose:
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")
            
            result = extractor.extract_tasks_from_page(
                page_num, use_split_analysis=True, split_mode=split_mode
            )
            
            storage.save_page_result(page_num, result)
            results.append(result)
            
            if verbose:
                tasks_count = len(result.get("tasks", []))
                error = result.get("error", "")
                if error:
                    logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å –æ—à–∏–±–∫–æ–π: {error}")
                else:
                    logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ: {tasks_count} –∑–∞–¥–∞—á")
        else:
            if verbose:
                logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} —É–∂–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
    
    return results


@click.command()
@click.argument('pdf_file', type=click.Path(exists=True))
@click.argument('output_csv', type=click.Path())
@click.option('--force', is_flag=True, help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã')
@click.option('--start-page', type=int, default=1, help='–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--end-page', type=int, default=None, help='–ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--production', is_flag=True, help='Production —Ä–µ–∂–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è')
@click.option('--verbose', is_flag=True, help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
@click.option('--parallel', is_flag=True, help='üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–û: –í–∫–ª—é—á–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ)')
@click.option('--max-concurrent', type=int, default=2, help='–ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è --parallel (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2 –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –ø–ª–∞–Ω–∞, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–µ –±–æ–ª–µ–µ 3)')
@click.option('--batch-size', type=int, default=5, help='–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)')
@click.option('--provider', type=click.Choice(['openai', 'gemini', 'claude']), default='gemini', help='–ü—Ä–æ–≤–∞–π–¥–µ—Ä –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ API (openai, gemini, claude)')
@click.option('--split-analysis', is_flag=True, default=True, help='üéØ –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø: –†–∞–∑–¥–µ–ª—è—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–Ω–æ–≥–æ–∫–æ–ª–æ–Ω–æ—á–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤–∫–ª—é—á–µ–Ω–æ)')
@click.option('--no-split', is_flag=True, help='–û—Ç–∫–ª—é—á–∏—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —Ü–µ–ª–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã)')
@click.option('--split-mode', type=click.Choice(['original', 'vertical', 'horizontal', 'grid']), default='vertical', help='üéØ –†–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: original (–±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è), vertical (–ª–µ–≤–æ/–ø—Ä–∞–≤–æ), horizontal (–≤–µ—Ä—Ö/–Ω–∏–∑), grid (—Å–µ—Ç–∫–∞ 2x2)')
def process_textbook_pure_vision_fixed(pdf_file, output_csv, force, start_page, end_page, 
                                      production, verbose, parallel, max_concurrent, batch_size, 
                                      provider, split_analysis, no_split, split_mode):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É—á–µ–±–Ω–∏–∫ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è OpenAI Vision API.
    
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –∏–∑ PDF —Ñ–∞–π–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV.
    """
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if production:
        setup_production_logger()
    else:
        setup_development_logger()
    
    logger = get_logger(__name__)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
    if no_split:
        split_mode = "original"
        split_analysis = False
    elif not split_analysis:
        split_mode = "original"
    
    logger.info("=" * 60)
    logger.info("üöÄ –ó–ê–ü–£–°–ö OCR-OCD Pure Vision Fixed")
    logger.info("=" * 60)
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä
    provider_enum = VisionProvider(provider)
    
    logger.info(f"üìñ PDF —Ñ–∞–π–ª: {pdf_file}")
    logger.info(f"üìä –í—ã—Ö–æ–¥–Ω–æ–π CSV: {output_csv}")
    logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü—ã: {start_page}-{end_page if end_page else '–∫–æ–Ω–µ—Ü'}")
    logger.info(f"ü§ñ –ü—Ä–æ–≤–∞–π–¥–µ—Ä API: {provider.upper()}")
    logger.info(f"üîß –†–µ–∂–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: {split_mode}")
    logger.info(f"‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {'–í–ö–õ' if parallel else '–í–´–ö–õ'}")
    logger.info(f"üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞: {'–î–ê' if force else '–ù–ï–¢'}")
    logger.info("=" * 60)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        extractor = TaskExtractor(pdf_file, provider_enum)
        total_pages = extractor.get_total_pages()
        
        if end_page is None:
            end_page = total_pages
        
        logger.info(f"üìö –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ PDF: {total_pages}")
        logger.info(f"üéØ –°—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {end_page - start_page + 1}")
        
        # –°–æ–∑–¥–∞–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        file_identifier = FileIdentifier.generate(pdf_file)
        storage_dir = Path("temp") / file_identifier / "results"
        storage = ResultStorage(storage_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        all_processed_pages = storage.get_processed_pages()
        successful_pages = storage.get_successful_pages()
        failed_pages = storage.get_failed_pages()
        
        if all_processed_pages and not force:
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(all_processed_pages)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful_pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")
            logger.info(f"‚ùå –° –æ—à–∏–±–∫–∞–º–∏: {len(failed_pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")
            
            # –î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            processed_pages = successful_pages
        else:
            processed_pages = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        start_time = time.time()
        
        if parallel:
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            parallel_processor = ParallelProcessor(
                max_concurrent_requests=max_concurrent,
                requests_per_minute=60  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ Gemini
            )
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            results = asyncio.run(process_pages_parallel(
                extractor, parallel_processor, storage,
                start_page, end_page, processed_pages,
                force, verbose, batch_size, split_mode
            ))
        else:
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
            results = process_pages_sequential(
                extractor, storage, start_page, end_page,
                processed_pages, force, verbose, split_mode
            )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results = storage.load_all_results()
        
        # –°–æ–∑–¥–∞–µ–º CSV —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
        create_pure_vision_fixed_csv(successful_results, output_csv)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        end_time = time.time()
        processing_time = end_time - start_time
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –∏—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ—à–∏–±–∫–∞–º–∏ –∏–∑ CSV
        successful_results = [r for r in all_results if not r.get("error")]
        failed_results = [r for r in all_results if r.get("error")]
        
        total_tasks = sum(len(result.get("tasks", [])) for result in successful_results)
        successful_pages = len(successful_results)
        failed_pages = len(failed_results)
        
        logger.info("=" * 60)
        logger.info("‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        logger.info("=" * 60)
        logger.info(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.1f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(all_results)}")
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–≤ CSV): {successful_pages}")
        logger.info(f"‚ùå –°—Ç—Ä–∞–Ω–∏—Ü —Å –æ—à–∏–±–∫–∞–º–∏ (–∏—Å–∫–ª—é—á–µ–Ω—ã): {failed_pages}")
        logger.info(f"üìù –í—Å–µ–≥–æ –∑–∞–¥–∞—á –≤ CSV: {total_tasks}")
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_csv}")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


def create_pure_vision_fixed_csv(results: List[Dict], output_path: str) -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç CSV —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    –°—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ—à–∏–±–∫–∞–º–∏ –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –∏–∑ CSV –∏ —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è.
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü
        output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É
    """
    import csv
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è CSV (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã)
    csv_data = []
    
    for page_result in results:
        page_number = page_result.get("page_number", "unknown")
        tasks = page_result.get("tasks", [])
        
        if not tasks:
            # –ï—Å–ª–∏ –∑–∞–¥–∞—á –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
            csv_data.append({
                "page_number": page_number,
                "task_number": "",
                "task_text": "",
                "task_type": "",
                "difficulty": "",
                "part": "",
                "analysis_method": page_result.get("analysis_method", ""),
                "error": ""
            })
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É
            for task in tasks:
                csv_data.append({
                    "page_number": page_number,
                    "task_number": task.get("number", ""),
                    "task_text": task.get("text", ""),
                    "task_type": task.get("type", ""),
                    "difficulty": task.get("difficulty", ""),
                    "part": task.get("part", ""),
                    "analysis_method": page_result.get("analysis_method", ""),
                    "error": ""
                })
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV —Ñ–∞–π–ª
    with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = [
            "page_number", "task_number", "task_text", "task_type", 
            "difficulty", "part", "analysis_method", "error"
        ]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        writer.writeheader()
        writer.writerows(csv_data)


if __name__ == "__main__":
    process_textbook_pure_vision_fixed() 