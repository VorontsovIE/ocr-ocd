#!/usr/bin/env python3
"""
OCR-OCD Pure Vision Fixed: –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è OpenAI
==================================================

–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —á–∏—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞:
- üìñ PDF ‚Üí –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü
- üñºÔ∏è –ü—Ä—è–º–æ–π GPT-4 Vision API ‚Üí –∞–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á  
- üìä CSV ‚Üí —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–° —Ä–∞–±–æ—á–µ–π –ø—Ä—è–º–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π OpenAI!
"""

import sys
import json
import time
import base64
import click
import openai
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.core.pdf_processor import PDFProcessor
from src.utils.logger import setup_development_logger, setup_production_logger, get_logger


class DirectVisionAPI:
    """–ü—Ä—è–º–æ–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è GPT-4 Vision API (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞–±–æ—á–∏–π)."""
    
    def __init__(self):
        load_dotenv()
        self.client = openai.OpenAI()
        self.logger = get_logger(__name__)
        
    def extract_tasks_from_page(self, image_data: bytes, page_number: int) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä—è–º–æ–π GPT-4 Vision API."""
        
        # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        b64_image = base64.b64encode(image_data).decode('utf-8')
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_number} –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—á–µ–±–Ω–∏–∫–∞ –¥–ª—è 1 –∫–ª–∞—Å—Å–∞.

üéØ –ó–ê–î–ê–ß–ê: –ù–∞–π–¥–∏ –í–°–ï –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.

üìù –ß–¢–û –ò–°–ö–ê–¢–¨:
‚Ä¢ –í–æ–ø—Ä–æ—Å—ã: "–°–∫–æ–ª—å–∫–æ...?", "–ì–¥–µ...?", "–ß—Ç–æ...?"
‚Ä¢ –ö–æ–º–∞–Ω–¥—ã: "–ü–æ–∫–∞–∂–∏...", "–ù–∞–π–¥–∏...", "–†–µ—à–∏...", "–ü–æ–ª–æ–∂–∏..."
‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã: —á–∏—Å–ª–∞, –≤—ã—Ä–∞–∂–µ–Ω–∏—è (2+3, 5-1)
‚Ä¢ –°—Ä–∞–≤–Ω–µ–Ω–∏—è: "–±–æ–ª—å—à–µ/–º–µ–Ω—å—à–µ", "–¥–ª–∏–Ω–Ω–µ–µ/–∫–æ—Ä–æ—á–µ"
‚Ä¢ –°—á—ë—Ç –æ–±—ä–µ–∫—Ç–æ–≤: "–ø–æ—Å—á–∏—Ç–∞–π...", "—Å–æ—Å—á–∏—Ç–∞–π..."

üìä –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{{
  "page_number": {page_number},
  "tasks": [
    {{
      "task_number": "1",
      "task_text": "–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏",
      "has_image": true
    }},
    {{
      "task_number": "2", 
      "task_text": "—Å–ª–µ–¥—É—é—â–∞—è –∑–∞–¥–∞—á–∞",
      "has_image": false
    }}
  ]
}}

‚ú® –í–ê–ñ–ù–û: 
- –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ –≤–∏–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π "unknown-1", "unknown-2"
- –í–∫–ª—é—á–∞–π –¥–∞–∂–µ –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–¥–∞—á–∏
- –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""

        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64_image}"}}
                        ]
                    }
                ],
                max_tokens=2000,
                temperature=0.1
            )
            
            processing_time = time.time() - start_time
            content = response.choices[0].message.content
            
            self.logger.info(f"GPT-4 Vision response for page {page_number}: {len(content)} chars")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
            try:
                parsed_data = json.loads(content)
                json_valid = True
                self.logger.debug(f"Valid JSON parsed for page {page_number}")
            except json.JSONDecodeError as e:
                # –ï—Å–ª–∏ –Ω–µ JSON, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞
                json_valid = False
                self.logger.warning(f"JSON parse failed for page {page_number}: {e}")
                
                # –ò—â–µ–º JSON –±–ª–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    try:
                        parsed_data = json.loads(json_match.group())
                        json_valid = True
                        self.logger.info(f"Extracted JSON from text for page {page_number}")
                    except json.JSONDecodeError:
                        parsed_data = self._create_fallback_structure(content, page_number)
                else:
                    parsed_data = self._create_fallback_structure(content, page_number)
            
            return {
                "success": True,
                "response": parsed_data,
                "processing_time": processing_time,
                "json_valid": json_valid,
                "model": response.model,
                "tokens": response.usage.total_tokens if response.usage else 0,
                "raw_content": content[:200] + "..." if len(content) > 200 else content
            }
            
        except Exception as e:
            self.logger.error(f"API error for page {page_number}: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": 0,
                "page_number": page_number
            }
    
    def _create_fallback_structure(self, content: str, page_number: int) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞—ë—Ç fallback —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–≥–¥–∞ JSON –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª—Å—è."""
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∑–∞–¥–∞—á–∏ –≤ —Ç–µ–∫—Å—Ç–µ
        lines = content.split('\n')
        tasks = []
        
        for i, line in enumerate(lines, 1):
            line = line.strip()
            if len(line) > 10 and any(keyword in line.lower() for keyword in 
                                     ['—Å–∫–æ–ª—å–∫–æ', '–Ω–∞–π–¥–∏', '—Ä–µ—à–∏', '–ø–æ–∫–∞–∂–∏', '–ø–æ–ª–æ–∂–∏', '?', '–∑–∞–¥–∞—á']):
                tasks.append({
                    "task_number": f"extracted-{i}",
                    "task_text": line,
                    "has_image": True
                })
        
        if not tasks:
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –±–µ—Ä—ë–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞–∫ –æ–¥–Ω—É –∑–∞–¥–∞—á—É
            tasks.append({
                "task_number": "fallback-1",
                "task_text": content[:300] + "..." if len(content) > 300 else content,
                "has_image": False
            })
        
        return {
            "page_number": page_number,
            "tasks": tasks
        }


class PureVisionFixedExtractor:
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è Pure Vision —Å–∏—Å—Ç–µ–º–∞ —Å –ø—Ä—è–º–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π OpenAI."""
    
    def __init__(self, pdf_path: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ Pure Vision —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞.
        
        Args:
            pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
        """
        self.logger = get_logger(__name__)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.pdf_processor = PDFProcessor(pdf_path)
        self.vision_api = DirectVisionAPI()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º PDF
        self.pdf_processor.load_pdf()
        
        self.logger.info(f"Pure Vision Fixed extractor initialized: {pdf_path}")
    
    def extract_tasks_from_page(self, page_number: int) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π Pure Vision.
        
        Args:
            page_number: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (1-based)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        """
        start_time = time.time()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_image = self.pdf_processor.convert_page_to_image(page_number - 1, save_to_file=False)  # 0-based index
            
            if not page_image:
                return {
                    "page_number": page_number,
                    "tasks": [],
                    "processing_time": time.time() - start_time,
                    "method": "pure_vision_fixed_no_image",
                    "error": f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}"
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π GPT-4 Vision API
            self.logger.debug(f"Analyzing page {page_number} with Direct GPT-4 Vision")
            
            api_result = self.vision_api.extract_tasks_from_page(page_image, page_number)
            
            if not api_result.get('success', False):
                return {
                    "page_number": page_number,
                    "tasks": [],
                    "processing_time": time.time() - start_time,
                    "method": "pure_vision_fixed_api_failed",
                    "error": f"Direct Vision API failed: {api_result.get('error', 'Unknown error')}"
                }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ GPT
            parsed_response = api_result.get('response', {})
            tasks_data = parsed_response.get('tasks', [])
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç
            tasks = []
            for i, task_data in enumerate(tasks_data, 1):
                task = {
                    'task_number': task_data.get('task_number', f"fixed-{page_number}-{i}"),
                    'task_text': task_data.get('task_text', ''),
                    'has_image': task_data.get('has_image', False),
                    'extraction_method': 'pure_vision_fixed_direct',
                    'vision_api_used': True,
                    'api_model': api_result.get('model', 'gpt-4o'),
                    'processing_confidence': self._calculate_confidence(task_data, api_result),
                    'pure_vision_fixed': True
                }
                tasks.append(task)
            
            processing_time = time.time() - start_time
            
            self.logger.debug(f"Pure Vision Fixed extracted {len(tasks)} tasks from page {page_number}")
            
            return {
                "page_number": page_number,
                "tasks": tasks,
                "processing_time": processing_time,
                "method": "pure_vision_fixed_success",
                "api_model": api_result.get('model', 'gpt-4o'),
                "api_tokens": api_result.get('tokens', 0),
                "api_time": api_result.get('processing_time', 0),
                "json_valid": api_result.get('json_valid', False),
                "raw_response": api_result.get('raw_content', '')
            }
            
        except Exception as e:
            self.logger.error(f"Error extracting tasks from page {page_number}: {e}")
            return {
                "page_number": page_number,
                "tasks": [],
                "processing_time": time.time() - start_time,
                "method": "pure_vision_fixed_error",
                "error": str(e)
            }
    
    def _calculate_confidence(self, task_data: Dict[str, Any], api_result: Dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç confidence score –¥–ª—è Pure Vision Fixed."""
        
        confidence = 0.8  # –ë–∞–∑–æ–≤—ã–π confidence –¥–ª—è Direct API
        
        # –ë–æ–Ω—É—Å –∑–∞ —É—Å–ø–µ—à–Ω—ã–π JSON –ø–∞—Ä—Å–∏–Ω–≥
        if api_result.get('json_valid', False):
            confidence += 0.1
        
        # –ë–æ–Ω—É—Å –∑–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        task_text = task_data.get('task_text', '').lower()
        math_keywords = ['—Å–∫–æ–ª—å–∫–æ', '–Ω–∞–π–¥–∏', '—Ä–µ—à–∏', '–ø–æ–∫–∞–∂–∏', '–ø–æ–ª–æ–∂–∏', '–ø–æ—Å—á–∏—Ç–∞–π', '?', '+', '-', '=']
        keyword_count = sum(1 for keyword in math_keywords if keyword in task_text)
        confidence += min(keyword_count * 0.02, 0.1)
        
        return min(confidence, 1.0)


class PureVisionFixedStorage:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–ª—è Pure Vision Fixed."""
    
    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
    def save_page_result(self, page_number: int, page_data: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç Pure Vision Fixed –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        file_path = self.storage_dir / f"pure_vision_fixed_page_{page_number:03d}.json"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Pure Vision Fixed
        page_data.update({
            'processed_at': datetime.now().isoformat(),
            'page_number': page_number,
            'storage_version': '5.0-pure-vision-fixed',
            'architecture': 'pure_gpt4_vision_direct_api'
        })
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(page_data, f, ensure_ascii=False, indent=2)
    
    def load_page_result(self, page_number: int) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç Pure Vision Fixed –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        file_path = self.storage_dir / f"pure_vision_fixed_page_{page_number:03d}.json"
        
        if not file_path.exists():
            return None
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Pure Vision Fixed —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}")
            return None
    
    def get_processed_pages(self) -> List[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü."""
        processed = []
        
        for file_path in sorted(self.storage_dir.glob("pure_vision_fixed_page_*.json")):
            try:
                page_num = int(file_path.stem.split('_')[4])
                processed.append(page_num)
            except (ValueError, IndexError):
                continue
                
        return sorted(processed)
    
    def load_all_results(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ Pure Vision Fixed —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        results = []
        
        for page_num in self.get_processed_pages():
            page_data = self.load_page_result(page_num)
            if page_data:
                results.append(page_data)
        
        return results
    
    def clear_storage(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã Pure Vision Fixed."""
        for file_path in self.storage_dir.glob("pure_vision_fixed_page_*.json"):
            file_path.unlink()


@click.command()
@click.argument('pdf_file', type=click.Path(exists=True))
@click.argument('output_csv', type=click.Path())
@click.option('--force', is_flag=True, help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã')
@click.option('--start-page', type=int, default=1, help='–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--end-page', type=int, default=None, help='–ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--production', is_flag=True, help='Production —Ä–µ–∂–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è')
@click.option('--verbose', is_flag=True, help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
def process_textbook_pure_vision_fixed(pdf_file, output_csv, force, start_page, end_page, production, verbose):
    """
    OCR-OCD Pure Vision Fixed: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –ø—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è GPT-4 Vision.
    
    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å —Ä–∞–±–æ—á–∏–º Direct OpenAI API:
    - PDF ‚Üí –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü ‚Üí –ø—Ä—è–º–æ–π GPT-4 Vision ‚Üí CSV
    """
    
    print("üöÄüîß OCR-OCD Pure Vision Fixed: Direct OpenAI API")
    print("=" * 55)
    print(f"üìñ PDF —Ñ–∞–π–ª: {pdf_file}")
    print(f"üìä –í—ã–≤–æ–¥: {output_csv}")
    print(f"üîÑ Force —Ä–µ–∂–∏–º: {'‚úÖ' if force else '‚ùå'}")
    print(f"üéØ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –ø—Ä—è–º–æ–π OpenAI API")
    print(f"‚ú® –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞–±–æ—á–∏–π –º–µ—Ç–æ–¥")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if production:
        setup_production_logger()
    else:
        setup_development_logger()
    
    logger = get_logger(__name__)
    
    # –°–æ–∑–¥–∞—ë–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    paths = {
        'output': Path("output"),
        'temp': Path("temp"), 
        'logs': Path("logs"),
        'storage': Path("temp/processed_pages_pure_vision_fixed")
    }
    
    for path in paths.values():
        path.mkdir(parents=True, exist_ok=True)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pure Vision Fixed —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    storage = PureVisionFixedStorage(paths['storage'])
    
    if force:
        print("üóëÔ∏è  Force —Ä–µ–∂–∏–º: –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        storage.clear_storage()
    
    start_time = datetime.now()
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pure Vision Fixed —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
        print(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pure Vision Fixed —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞...")
        extractor = PureVisionFixedExtractor(pdf_file)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PDF
        total_pages = extractor.pdf_processor.get_page_count()
        
        if end_page is None:
            end_page = total_pages
        else:
            end_page = min(end_page, total_pages)
        
        print(f"‚úÖ Pure Vision Fixed —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        print(f"üìö PDF: {total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
        print(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü—ã {start_page}-{end_page}")
        print(f"üîß –ü—Ä—è–º–æ–π OpenAI API: –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        processed_pages = set(storage.get_processed_pages())
        
        if processed_pages and not force:
            print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(processed_pages)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")
            print(f"üìä –ü–æ—Å–ª–µ–¥–Ω—è—è: {max(processed_pages) if processed_pages else 'none'}")
        
        # –°—á—ë—Ç—á–∏–∫–∏
        processed_count = 0
        skipped_count = 0 
        error_count = 0
        total_tasks = 0
        total_tokens = 0
        total_api_time = 0
        
        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º Pure Vision Fixed –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        
        for page_num in range(start_page, end_page + 1):
            page_start_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
            if not force and page_num in processed_pages:
                skipped_count += 1
                if verbose:
                    print(f"‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞)")
                continue
            
            try:
                progress = (page_num - start_page + 1) / (end_page - start_page + 1) * 100
                print(f"\nüìñ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{end_page} ({progress:.1f}%)")
                
                # Pure Vision Fixed –æ–±—Ä–∞–±–æ—Ç–∫–∞
                if verbose:
                    print(f"  üîß Pure Vision Fixed –∞–Ω–∞–ª–∏–∑...")
                
                result = extractor.extract_tasks_from_page(page_num)
                
                if 'error' in result:
                    error_count += 1
                    print(f"     ‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                    continue
                
                tasks = result['tasks']
                method = result.get('method', 'unknown')
                api_time = result.get('api_time', 0)
                api_tokens = result.get('api_tokens', 0)
                json_valid = result.get('json_valid', False)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á—ë—Ç—á–∏–∫–∏
                total_tokens += api_tokens
                total_api_time += api_time
                
                if verbose:
                    print(f"  ‚úÖ Pure Vision Fixed –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
                    print(f"  üéØ –ú–µ—Ç–æ–¥: {method}")
                    print(f"  üìä JSON –≤–∞–ª–∏–¥–Ω—ã–π: {'‚úÖ' if json_valid else '‚ùå'}")
                    print(f"  üî§ Tokens: {api_tokens}")
                    print(f"  ‚è±Ô∏è API –≤—Ä–µ–º—è: {api_time:.2f}s")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                page_result = {
                    'page_number': page_num,
                    'tasks': tasks,
                    'processing_time': result['processing_time'],
                    'method': method,
                    'api_model': result.get('api_model', 'gpt-4o'),
                    'api_tokens': api_tokens,
                    'api_time': api_time,
                    'json_valid': json_valid,
                    'task_count': len(tasks),
                    'raw_response': result.get('raw_response', '')
                }
                
                storage.save_page_result(page_num, page_result)
                
                processed_count += 1
                total_tasks += len(tasks)
                
                processing_time = time.time() - page_start_time
                print(f"     ‚úÖ –ó–∞–¥–∞—á: {len(tasks)}, –í—Ä–µ–º—è: {processing_time:.2f}s")
                
                if verbose and tasks:
                    for i, task in enumerate(tasks[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        confidence = task.get('processing_confidence', 0)
                        print(f"       {i}. [conf:{confidence:.2f}] {task['task_number']}: {task['task_text'][:50]}...")
                
                # –ü–∞—É–∑–∞ –¥–ª—è API
                time.sleep(1.0)  # –†–∞–∑—É–º–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                
            except Exception as e:
                logger.error(f"Error processing page {page_num}: {e}")
                print(f"     ‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                error_count += 1
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüíæ –°–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö Pure Vision Fixed —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        all_results = storage.load_all_results()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ CSV
        if all_results:
            print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ Pure Vision Fixed CSV —Ñ–∞–π–ª–∞...")
            create_pure_vision_fixed_csv(all_results, output_csv)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = (datetime.now() - start_time).total_seconds()
        avg_api_time = total_api_time / processed_count if processed_count > 0 else 0
        estimated_cost = total_tokens * 0.00001  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å
        
        print(f"\nüéâ PURE VISION FIXED –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"=" * 55)
        print(f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   üìö –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}")
        print(f"   ‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
        print(f"   ‚ùå –û—à–∏–±–æ–∫: {error_count}")
        print(f"   üìù –ó–∞–¥–∞—á –∏–∑–≤–ª–µ—á–µ–Ω–æ: {total_tasks}")
        print(f"   üî§ –í—Å–µ–≥–æ tokens: {total_tokens}")
        print(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}s ({total_time/60:.1f} –º–∏–Ω—É—Ç)")
        print(f"   ‚ö° –°—Ä–µ–¥–Ω–µ–µ API –≤—Ä–µ–º—è: {avg_api_time:.2f}s")
        print(f"   üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${estimated_cost:.4f}")
        if processed_count > 0:
            print(f"   üìà –°—Ä–µ–¥–Ω–µ–µ –∑–∞–¥–∞—á/—Å—Ç—Ä–∞–Ω–∏—Ü–∞: {total_tasks/processed_count:.1f}")
            print(f"   üèÉ –°–∫–æ—Ä–æ—Å—Ç—å: {processed_count/total_time*60:.1f} —Å—Ç—Ä–∞–Ω–∏—Ü/—á–∞—Å")
        
        print(f"\nüìÅ Pure Vision Fixed CSV: {output_csv}")
        print(f"üéØ –ú–µ—Ç–æ–¥: –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è OpenAI API")
        print(f"‚ú® –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞–±–æ—á–∏–π –ø–æ–¥—Ö–æ–¥")
        
        return True
        
    except Exception as e:
        logger.error(f"Critical Pure Vision Fixed error: {e}")
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ Pure Vision Fixed: {e}")
        return False


def create_pure_vision_fixed_csv(results: List[Dict], output_path: str) -> None:
    """–°–æ–∑–¥–∞—ë—Ç Pure Vision Fixed CSV —Ñ–∞–π–ª –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    
    all_tasks = []
    
    for page_result in results:
        page_num = page_result['page_number']
        processing_time = page_result.get('processing_time', 0)
        method = page_result.get('method', 'unknown')
        api_model = page_result.get('api_model', 'gpt-4o')
        api_tokens = page_result.get('api_tokens', 0)
        api_time = page_result.get('api_time', 0)
        json_valid = page_result.get('json_valid', False)
        
        for task_data in page_result.get('tasks', []):
            task_row = {
                'page_number': page_num,
                'task_number': task_data.get('task_number', 'unknown'),
                'task_text': task_data.get('task_text', ''),
                'has_image': task_data.get('has_image', False),
                'processing_confidence': task_data.get('processing_confidence', 0.0),
                'processing_time': processing_time,
                'api_method': method,
                'api_model': api_model,
                'api_tokens': api_tokens,
                'api_time': api_time,
                'extraction_method': task_data.get('extraction_method', 'pure_vision_fixed_direct'),
                'vision_api_used': task_data.get('vision_api_used', True),
                'pure_vision_fixed': task_data.get('pure_vision_fixed', True),
                'json_valid': json_valid,
                'extracted_at': page_result.get('processed_at', ''),
                'word_count': len(task_data.get('task_text', '').split()),
                'system_type': 'pure_gpt4_vision_fixed',
                'architecture': 'pdf_direct_openai_api'
            }
            all_tasks.append(task_row)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    all_tasks.sort(key=lambda x: (x['page_number'], -x['processing_confidence']))
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV
    import csv
    with open(output_path, 'w', newline='', encoding='utf-8') as f:
        if all_tasks:
            fieldnames = list(all_tasks[0].keys())
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_tasks)
    
    print(f"‚úÖ Pure Vision Fixed CSV —Å–æ–∑–¥–∞–Ω: {len(all_tasks)} –∑–∞–¥–∞—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
    print(f"üìä –ü–æ–ª—è: pure_vision_fixed, api_tokens, api_time, json_valid")


if __name__ == "__main__":
    process_textbook_pure_vision_fixed() 