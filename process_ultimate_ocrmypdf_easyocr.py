#!/usr/bin/env python3
"""
OCR-OCD Ultimate: OCRmyPDF-EasyOCR Optimized
============================================

–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –∏–∑ OCRmyPDF-EasyOCR —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- EasyOCR —á–µ—Ä–µ–∑ GPU (–≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)
- –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è PDF —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- –ë–ª–æ—á–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
- Confidence 100% –¥–ª—è –≤—Å–µ—Ö —Å–ª–æ–≤
"""

import sys
import json
import time
import click
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import re

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.utils.logger import setup_development_logger, setup_production_logger, get_logger
from src.utils.ocrmypdf_easyocr_parser import OCRmyPDFEasyOCRParser, OCRTextBlock


class UltimateTaskExtractor:
    """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–∞—è –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –∏–∑ OCRmyPDF-EasyOCR –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(self, ocr_file_path: str):
        self.ocr_parser = OCRmyPDFEasyOCRParser(ocr_file_path)
        
        # –£—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
        self.question_patterns = [
            r'—Å–∫–æ–ª—å–∫–æ\s+.*?\?',          # –°–∫–æ–ª—å–∫–æ ... ?
            r'–≥–¥–µ\s+.*?\?',              # –ì–¥–µ ... ?
            r'—á—Ç–æ\s+.*?\?',              # –ß—Ç–æ ... ?
            r'–∫–∞–∫\s+.*?\?',              # –ö–∞–∫ ... ?
            r'–∫–∞–∫–æ–π\s+.*?\?',            # –ö–∞–∫–æ–π ... ?
            r'–∫–∞–∫–∞—è\s+.*?\?',            # –ö–∞–∫–∞—è ... ?
            r'–∫–∞–∫–∏–µ\s+.*?\?',            # –ö–∞–∫–∏–µ ... ?
        ]
        
        self.task_command_patterns = [
            r'—Ä–µ—à–∏.*',
            r'–Ω–∞–π–¥–∏.*',
            r'–≤—ã—á–∏—Å–ª–∏.*',
            r'–ø–æ—Å—á–∏—Ç–∞–π.*',
            r'–ø–æ–∫–∞–∂–∏.*',
            r'–ø–æ–ª–æ–∂–∏.*',
            r'–Ω–∞—Ä–∏—Å—É–π.*',
            r'–æ—Ç–º–µ—Ç—å.*',
            r'–æ–±–≤–µ–¥–∏.*',
            r'–ø–æ–¥—á–µ—Ä–∫–Ω–∏.*'
        ]
        
        self.comparison_patterns = [
            r'–±–æ–ª—å—à–µ.*–º–µ–Ω—å—à–µ',
            r'–¥–ª–∏–Ω–Ω–µ–µ.*–∫–æ—Ä–æ—á–µ',
            r'–≤—ã—à–µ.*–Ω–∏–∂–µ',
            r'—à–∏—Ä–µ.*—É–∂–µ',
            r'—Ç–æ–ª—â–µ.*—Ç–æ–Ω—å—à–µ'
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è has_image
        self.visual_keywords = [
            '—Ä–∏—Å—É–Ω', '–∫–∞—Ä—Ç–∏–Ω', '—Å—Ö–µ–º', '–¥–∏–∞–≥—Ä–∞–º–º', '–≥—Ä–∞—Ñ–∏–∫', '—á–µ—Ä—Ç—ë–∂', 
            '–ø–æ–∫–∞–∂–∏', '–Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–æ', '–∏–∑–æ–±—Ä–∞–∂', '–≤–∏–¥–∏—à—å', '–Ω–∞—Ä–∏—Å—É–π',
            '–ø–∞–ª–æ—á–∫', '–∫—Ä—É–∂–∫–æ–≤', '—Ç–æ—á–µ–∫', '–ª–∏–Ω–∏–π', '—Ñ–∏–≥—É—Ä'
        ]
        
    def extract_tasks_from_page(self, page_number: int) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É—è OCRmyPDF-EasyOCR —Å—Ç—Ä—É–∫—Ç—É—Ä—É."""
        
        try:
            start_time = time.time()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ OCR –¥–∞–Ω–Ω—ã–µ
            ocr_page = self.ocr_parser.parse_page(page_number)
            
            if not ocr_page:
                return {
                    "page_number": page_number,
                    "tasks": [],
                    "processing_time": time.time() - start_time,
                    "method": "ultimate_ocrmypdf_easyocr",
                    "error": "No OCRmyPDF-EasyOCR data found"
                }
            
            # –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–¥–∞—á
            tasks = []
            
            # –ú–µ—Ç–æ–¥ 1: –ê–Ω–∞–ª–∏–∑ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–æ–≤
            math_block_tasks = self._extract_from_math_blocks(ocr_page)
            tasks.extend(math_block_tasks)
            
            # –ú–µ—Ç–æ–¥ 2: –ê–Ω–∞–ª–∏–∑ –±–ª–æ–∫–æ–≤ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏
            question_block_tasks = self._extract_from_question_blocks(ocr_page)
            tasks.extend(question_block_tasks)
            
            # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –ø–æ —à–∞–±–ª–æ–Ω–∞–º –∫–æ–º–∞–Ω–¥
            command_tasks = self._extract_command_tasks(ocr_page)
            tasks.extend(command_tasks)
            
            # –ú–µ—Ç–æ–¥ 4: –ê–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π
            comparison_tasks = self._extract_comparison_tasks(ocr_page)
            tasks.extend(comparison_tasks)
            
            # –ú–µ—Ç–æ–¥ 5: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–ª–æ–∫–æ–≤
            combined_tasks = self._extract_combined_block_tasks(ocr_page)
            tasks.extend(combined_tasks)
            
            # –û—á–∏—Å—Ç–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á
            tasks = self._optimize_and_clean_tasks(tasks, ocr_page)
            
            processing_time = time.time() - start_time
            
            return {
                "page_number": page_number,
                "tasks": tasks,
                "processing_time": processing_time,
                "method": "ultimate_ocrmypdf_easyocr",
                "ocr_stats": {
                    "total_words": ocr_page.word_count,
                    "total_blocks": ocr_page.block_count,
                    "avg_confidence": ocr_page.avg_confidence,
                    "math_blocks": len(ocr_page.get_math_blocks()),
                    "question_blocks": len(ocr_page.get_question_blocks()),
                    "numbers_found": ocr_page.get_numbers_and_operators()[:10]
                },
                "extraction_methods": {
                    "math_blocks": len(math_block_tasks),
                    "question_blocks": len(question_block_tasks),
                    "command_tasks": len(command_tasks),
                    "comparison_tasks": len(comparison_tasks),
                    "combined_tasks": len(combined_tasks)
                },
                "full_text": ocr_page.text,
                "ocr_engine": "OCRmyPDF-EasyOCR-GPU"
            }
            
        except Exception as e:
            return {
                "page_number": page_number,
                "tasks": [],
                "processing_time": 0,
                "method": "ultimate_ocrmypdf_easyocr",
                "error": str(e)
            }
    
    def _extract_from_math_blocks(self, ocr_page) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–æ–≤."""
        tasks = []
        math_blocks = ocr_page.get_math_blocks()
        
        for i, block in enumerate(math_blocks, 1):
            block_text = block.text.strip()
            if len(block_text) > 5:
                tasks.append({
                    "task_number": f"math-{i}",
                    "task_text": block_text,
                    "has_image": self._has_visual_indicators(block_text),
                    "confidence_score": 0.9,
                    "extraction_method": "math_block_analysis",
                    "block_info": {
                        "par_num": block.par_num,
                        "block_num": block.block_num,
                        "word_count": block.word_count,
                        "line_count": block.line_count,
                        "bbox": block.bbox
                    }
                })
        
        return tasks
    
    def _extract_from_question_blocks(self, ocr_page) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ –±–ª–æ–∫–æ–≤ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏."""
        tasks = []
        question_blocks = ocr_page.get_question_blocks()
        
        for i, block in enumerate(question_blocks, 1):
            block_text = block.text.strip()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –±–ª–æ–∫ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
            questions = self._split_into_questions(block_text)
            
            for j, question in enumerate(questions, 1):
                if len(question.strip()) > 5:
                    tasks.append({
                        "task_number": f"question-{i}-{j}",
                        "task_text": question.strip(),
                        "has_image": self._has_visual_indicators(question),
                        "confidence_score": 0.95,  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤
                        "extraction_method": "question_block_analysis",
                        "block_info": {
                            "par_num": block.par_num,
                            "block_num": block.block_num,
                            "question_index": j
                        }
                    })
        
        return tasks
    
    def _extract_command_tasks(self, ocr_page) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ –ø–æ –∫–æ–º–∞–Ω–¥–Ω—ã–º —à–∞–±–ª–æ–Ω–∞–º."""
        tasks = []
        task_num = 1
        
        for block in ocr_page.text_blocks:
            block_text = block.text.lower()
            
            for pattern in self.task_command_patterns:
                matches = re.finditer(pattern, block_text, re.IGNORECASE)
                for match in matches:
                    # –ò—â–µ–º –ø–æ–ª–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –∫–æ–º–∞–Ω–¥–æ–π
                    full_sentence = self._extract_full_sentence(block.text, match.start())
                    
                    if len(full_sentence.strip()) > 10:
                        tasks.append({
                            "task_number": f"command-{task_num}",
                            "task_text": full_sentence.strip(),
                            "has_image": self._has_visual_indicators(full_sentence),
                            "confidence_score": 0.85,
                            "extraction_method": f"command_pattern_{pattern[:10]}",
                            "match_info": {
                                "pattern": pattern,
                                "start_pos": match.start(),
                                "matched_text": match.group()
                            }
                        })
                        task_num += 1
        
        return tasks
    
    def _extract_comparison_tasks(self, ocr_page) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Å–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è–º–∏."""
        tasks = []
        task_num = 1
        
        for block in ocr_page.text_blocks:
            block_text = block.text.lower()
            
            for pattern in self.comparison_patterns:
                if re.search(pattern, block_text, re.IGNORECASE):
                    tasks.append({
                        "task_number": f"comparison-{task_num}",
                        "task_text": block.text.strip(),
                        "has_image": True,  # –°—Ä–∞–≤–Ω–µ–Ω–∏—è –æ–±—ã—á–Ω–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ
                        "confidence_score": 0.8,
                        "extraction_method": "comparison_analysis",
                        "comparison_type": pattern
                    })
                    task_num += 1
        
        return tasks
    
    def _extract_combined_block_tasks(self, ocr_page) -> List[Dict[str, Any]]:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–º–µ–∂–Ω—ã—Ö –±–ª–æ–∫–æ–≤."""
        tasks = []
        task_num = 1
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ –±–ª–æ–∫–∏ –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∑–∞–¥–∞—á
        for i in range(len(ocr_page.text_blocks) - 1):
            current_block = ocr_page.text_blocks[i]
            next_block = ocr_page.text_blocks[i + 1]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –±–ª–æ–∫ - –≤–æ–ø—Ä–æ—Å, –∞ —Å–ª–µ–¥—É—é—â–∏–π - –æ—Ç–≤–µ—Ç –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
            current_text = current_block.text.strip()
            next_text = next_block.text.strip()
            
            if (len(current_text) > 5 and len(next_text) > 5 and
                ('?' in current_text or any(cmd in current_text.lower() for cmd in ['–ø–æ–∫–∞–∂–∏', '–ø–æ–ª–æ–∂–∏', '–Ω–∞–π–¥–∏']))):
                
                combined_text = f"{current_text}\n{next_text}"
                
                tasks.append({
                    "task_number": f"combined-{task_num}",
                    "task_text": combined_text,
                    "has_image": self._has_visual_indicators(combined_text),
                    "confidence_score": 0.75,
                    "extraction_method": "combined_block_analysis",
                    "blocks_combined": [
                        {"par_num": current_block.par_num, "block_num": current_block.block_num},
                        {"par_num": next_block.par_num, "block_num": next_block.block_num}
                    ]
                })
                task_num += 1
        
        return tasks
    
    def _split_into_questions(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã."""
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–Ω–∞–∫–∞–º –≤–æ–ø—Ä–æ—Å–∞
        questions = re.split(r'\?+', text)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—á–∏—â–∞–µ–º
        result = []
        for i, q in enumerate(questions[:-1]):  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –æ–±—ã—á–Ω–æ –ø—É—Å—Ç–æ–π
            q = q.strip()
            if q:
                result.append(q + '?')
        
        return result
    
    def _extract_full_sentence(self, text: str, start_pos: int) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç –ø–æ–∑–∏—Ü–∏–∏."""
        # –ò—â–µ–º –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–∏–¥—ë–º –Ω–∞–∑–∞–¥ –¥–æ —Ç–æ—á–∫–∏ –∏–ª–∏ –Ω–∞—á–∞–ª–∞)
        sentence_start = start_pos
        while sentence_start > 0 and text[sentence_start - 1] not in '.!?\n':
            sentence_start -= 1
        
        # –ò—â–µ–º –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–∏–¥—ë–º –≤–ø–µ—Ä—ë–¥ –¥–æ —Ç–æ—á–∫–∏, –≤–æ–ø—Ä–æ—Å–∞, –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è)
        sentence_end = start_pos
        while sentence_end < len(text) and text[sentence_end] not in '.!?':
            sentence_end += 1
        
        if sentence_end < len(text):
            sentence_end += 1  # –í–∫–ª—é—á–∞–µ–º –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        
        return text[sentence_start:sentence_end].strip()
    
    def _has_visual_indicators(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ."""
        text_lower = text.lower()
        return any(keyword in text_lower for keyword in self.visual_keywords)
    
    def _optimize_and_clean_tasks(self, tasks: List[Dict], ocr_page) -> List[Dict]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏."""
        
        if not tasks:
            # –ï—Å–ª–∏ –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞—ë–º –æ–±—â—É—é –∑–∞–¥–∞—á—É –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_text = ocr_page.text.strip()
            if page_text and len(page_text) > 10:
                return [{
                    "task_number": "page-content-1",
                    "task_text": page_text[:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    "has_image": self._has_visual_indicators(page_text),
                    "confidence_score": 0.6,
                    "extraction_method": "page_content_fallback",
                    "page_info": {
                        "total_blocks": ocr_page.block_count,
                        "total_words": ocr_page.word_count
                    }
                }]
            else:
                return []
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É
        seen_texts = set()
        unique_tasks = []
        
        for task in tasks:
            text_normalized = re.sub(r'\s+', ' ', task['task_text'].strip().lower())
            if text_normalized and text_normalized not in seen_texts:
                seen_texts.add(text_normalized)
                unique_tasks.append(task)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤—É
        unique_tasks.sort(key=lambda t: t.get('confidence_score', 0), reverse=True)
        
        # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∑–∞–¥–∞—á–∏
        for i, task in enumerate(unique_tasks, 1):
            task['task_number'] = f"ultimate-{i}"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ OCR
            task.update({
                "page_ocr_confidence": ocr_page.avg_confidence,
                "page_word_count": ocr_page.word_count,
                "page_block_count": ocr_page.block_count,
                "extraction_source": "ocrmypdf_easyocr_gpu",
                "ocr_engine_details": "EasyOCR —á–µ—Ä–µ–∑ OCRmyPDF –ø–ª–∞–≥–∏–Ω"
            })
        
        return unique_tasks


class IntermediateStorage:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    
    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
    def save_page_result(self, page_number: int, page_data: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        file_path = self.storage_dir / f"page_{page_number:03d}.json"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        page_data.update({
            'processed_at': datetime.now().isoformat(),
            'page_number': page_number,
            'storage_version': '2.4-ultimate-ocrmypdf-easyocr'
        })
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(page_data, f, ensure_ascii=False, indent=2)
    
    def load_page_result(self, page_number: int) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
        file_path = self.storage_dir / f"page_{page_number:03d}.json"
        
        if not file_path.exists():
            return None
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_number}: {e}")
            return None
    
    def get_processed_pages(self) -> List[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü."""
        processed = []
        
        for file_path in sorted(self.storage_dir.glob("page_*.json")):
            try:
                page_num = int(file_path.stem.split('_')[1])
                processed.append(page_num)
            except (ValueError, IndexError):
                continue
                
        return sorted(processed)
    
    def load_all_results(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        results = []
        
        for page_num in self.get_processed_pages():
            page_data = self.load_page_result(page_num)
            if page_data:
                results.append(page_data)
        
        return results
    
    def clear_storage(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã."""
        for file_path in self.storage_dir.glob("page_*.json"):
            file_path.unlink()


@click.command()
@click.argument('ocr_file', type=click.Path(exists=True))
@click.argument('output_csv', type=click.Path())
@click.option('--force', is_flag=True, help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã')
@click.option('--start-page', type=int, default=1, help='–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--end-page', type=int, default=None, help='–ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--production', is_flag=True, help='Production —Ä–µ–∂–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è')
@click.option('--verbose', is_flag=True, help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
def process_textbook_ultimate(ocr_file, output_csv, force, start_page, end_page, production, verbose):
    """
    OCR-OCD Ultimate: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ OCRmyPDF-EasyOCR.
    
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é.
    """
    
    print("üöÄüìö OCR-OCD Ultimate: OCRmyPDF-EasyOCR Optimized")
    print("=" * 60)
    print(f"üîç OCRmyPDF-EasyOCR —Ñ–∞–π–ª: {ocr_file}")
    print(f"üìä –í—ã–≤–æ–¥: {output_csv}")
    print(f"üîÑ Force —Ä–µ–∂–∏–º: {'‚úÖ' if force else '‚ùå'}")
    print(f"‚ö° Ultimate Performance: ‚úÖ")
    print(f"üéØ EasyOCR —á–µ—Ä–µ–∑ GPU: ‚úÖ")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if production:
        setup_production_logger()
    else:
        setup_development_logger()
    
    logger = get_logger(__name__)
    
    # –°–æ–∑–¥–∞—ë–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    paths = {
        'output': Path("output"),
        'temp': Path("temp"), 
        'logs': Path("logs"),
        'storage': Path("temp/processed_pages_ultimate")
    }
    
    for path in paths.values():
        path.mkdir(parents=True, exist_ok=True)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    storage = IntermediateStorage(paths['storage'])
    
    if force:
        print("üóëÔ∏è  Force —Ä–µ–∂–∏–º: –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        storage.clear_storage()
    
    start_time = datetime.now()
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ultimate —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
        print(f"‚ö° –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ultimate —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞...")
        extractor = UltimateTaskExtractor(ocr_file)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        available_pages = extractor.ocr_parser.get_available_pages()
        
        if end_page is None:
            end_page = max(available_pages) if available_pages else start_page
        else:
            end_page = min(end_page, max(available_pages) if available_pages else end_page)
        
        print(f"‚úÖ OCRmyPDF-EasyOCR –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(available_pages)} —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ—Å—Ç—É–ø–Ω–æ")
        print(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞: —Å—Ç—Ä–∞–Ω–∏—Ü—ã {start_page}-{end_page}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        processed_pages = set(storage.get_processed_pages())
        
        if processed_pages and not force:
            print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(processed_pages)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")
            print(f"üìä –ü–æ—Å–ª–µ–¥–Ω—è—è: {max(processed_pages) if processed_pages else 'none'}")
        
        # –°—á—ë—Ç—á–∏–∫–∏
        processed_count = 0
        skipped_count = 0 
        error_count = 0
        total_tasks = 0
        total_extraction_methods = {
            "math_blocks": 0,
            "question_blocks": 0,
            "command_tasks": 0,
            "comparison_tasks": 0,
            "combined_tasks": 0
        }
        
        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º Ultimate –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        
        for page_num in range(start_page, end_page + 1):
            page_start_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if page_num not in available_pages:
                if verbose:
                    print(f"‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–µ—Ç OCRmyPDF –¥–∞–Ω–Ω—ã—Ö")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
            if not force and page_num in processed_pages:
                skipped_count += 1
                if verbose:
                    print(f"‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞)")
                continue
            
            try:
                progress = (page_num - start_page + 1) / (end_page - start_page + 1) * 100
                print(f"\nüìñ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{end_page} ({progress:.1f}%)")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Ultimate —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
                if verbose:
                    print(f"  ‚ö° Ultimate –∞–Ω–∞–ª–∏–∑...")
                
                result = extractor.extract_tasks_from_page(page_num)
                
                if 'error' in result:
                    error_count += 1
                    print(f"     ‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                    continue
                
                tasks = result['tasks']
                ocr_stats = result.get('ocr_stats', {})
                extraction_methods = result.get('extraction_methods', {})
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–µ—Ç–æ–¥–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                for method, count in extraction_methods.items():
                    total_extraction_methods[method] += count
                
                if verbose:
                    print(f"  ‚úÖ Ultimate –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
                    print(f"  üìä –ë–ª–æ–∫–æ–≤: {ocr_stats.get('total_blocks', 0)}, "
                          f"–°–ª–æ–≤: {ocr_stats.get('total_words', 0)}, "
                          f"Confidence: {ocr_stats.get('avg_confidence', 0)}%")
                    print(f"  üîç –ú–µ—Ç–æ–¥—ã: Math={extraction_methods.get('math_blocks', 0)}, "
                          f"Q={extraction_methods.get('question_blocks', 0)}, "
                          f"Cmd={extraction_methods.get('command_tasks', 0)}")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                page_result = {
                    'page_number': page_num,
                    'tasks': tasks,
                    'processing_time': result['processing_time'],
                    'ocr_stats': ocr_stats,
                    'extraction_methods': extraction_methods,
                    'api_method': 'ultimate_ocrmypdf_easyocr',
                    'task_count': len(tasks),
                    'full_text': result.get('full_text', '')
                }
                
                storage.save_page_result(page_num, page_result)
                
                processed_count += 1
                total_tasks += len(tasks)
                
                processing_time = time.time() - page_start_time
                print(f"     ‚úÖ –ó–∞–¥–∞—á: {len(tasks)}, –í—Ä–µ–º—è: {processing_time:.2f}s")
                
                if verbose and tasks:
                    for i, task in enumerate(tasks[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        method = task.get('extraction_method', 'unknown')
                        print(f"       {i}. [{method}] {task['task_number']}: {task['task_text'][:50]}...")
                
                # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞
                time.sleep(0.05)
                
            except Exception as e:
                logger.error(f"Error processing page {page_num}: {e}")
                print(f"     ‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                error_count += 1
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüíæ –°–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        all_results = storage.load_all_results()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ CSV
        if all_results:
            print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ Ultimate CSV —Ñ–∞–π–ª–∞...")
            create_ultimate_csv(all_results, output_csv)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = (datetime.now() - start_time).total_seconds()
        
        print(f"\nüéâ ULTIMATE –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"=" * 50)
        print(f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   üìö –°—Ç—Ä–∞–Ω–∏—Ü –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}")
        print(f"   ‚è≠Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
        print(f"   ‚ùå –û—à–∏–±–æ–∫: {error_count}")
        print(f"   üìù –ó–∞–¥–∞—á –∏–∑–≤–ª–µ—á–µ–Ω–æ: {total_tasks}")
        print(f"   üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: $0.00 (–±–µ—Å–ø–ª–∞—Ç–Ω–æ!)")
        print(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}s ({total_time/60:.1f} –º–∏–Ω—É—Ç)")
        if processed_count > 0:
            print(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {processed_count/total_time*60:.1f} —Å—Ç—Ä–∞–Ω–∏—Ü/–º–∏–Ω—É—Ç—É")
            print(f"   üìà –°—Ä–µ–¥–Ω–µ–µ –∑–∞–¥–∞—á/—Å—Ç—Ä–∞–Ω–∏—Ü–∞: {total_tasks/processed_count:.1f}")
        
        print(f"\nüîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ç–æ–¥–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:")
        for method, count in total_extraction_methods.items():
            print(f"   ‚Ä¢ {method}: {count} –∑–∞–¥–∞—á")
        
        print(f"\nüìÅ Ultimate CSV: {output_csv}")
        print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ: OCRmyPDF-EasyOCR —á–µ—Ä–µ–∑ GPU")
        
        return True
        
    except Exception as e:
        logger.error(f"Critical error: {e}")
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False


def create_ultimate_csv(results: List[Dict], output_path: str) -> None:
    """–°–æ–∑–¥–∞—ë—Ç Ultimate CSV —Ñ–∞–π–ª –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    
    all_tasks = []
    
    for page_result in results:
        page_num = page_result['page_number']
        processing_time = page_result.get('processing_time', 0)
        ocr_stats = page_result.get('ocr_stats', {})
        extraction_methods = page_result.get('extraction_methods', {})
        
        for task_data in page_result.get('tasks', []):
            task_row = {
                'page_number': page_num,
                'task_number': task_data.get('task_number', 'unknown'),
                'task_text': task_data.get('task_text', ''),
                'has_image': task_data.get('has_image', False),
                'confidence_score': task_data.get('confidence_score', 0.0),
                'processing_time': processing_time,
                'api_method': 'ultimate_ocrmypdf_easyocr',
                'extraction_method': task_data.get('extraction_method', 'unknown'),
                'page_ocr_confidence': task_data.get('page_ocr_confidence', 100),
                'page_word_count': task_data.get('page_word_count', 0),
                'page_block_count': task_data.get('page_block_count', 0),
                'extraction_source': task_data.get('extraction_source', 'ocrmypdf_easyocr_gpu'),
                'ocr_engine_details': task_data.get('ocr_engine_details', 'EasyOCR —á–µ—Ä–µ–∑ OCRmyPDF –ø–ª–∞–≥–∏–Ω'),
                'extracted_at': page_result.get('processed_at', ''),
                'word_count': len(task_data.get('task_text', '').split()),
                'system_type': 'ultimate_ocrmypdf_easyocr_gpu'
            }
            all_tasks.append(task_row)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    all_tasks.sort(key=lambda x: (x['page_number'], -x['confidence_score']))
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV
    import csv
    with open(output_path, 'w', newline='', encoding='utf-8') as f:
        if all_tasks:
            fieldnames = list(all_tasks[0].keys())
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_tasks)
    
    print(f"‚úÖ Ultimate CSV —Å–æ–∑–¥–∞–Ω: {len(all_tasks)} –∑–∞–¥–∞—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
    print(f"üìä –ü–æ–ª—è: extraction_method, ocr_engine_details, system_type")


if __name__ == "__main__":
    process_textbook_ultimate() 